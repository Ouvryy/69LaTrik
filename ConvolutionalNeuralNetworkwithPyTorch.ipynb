{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYdHsar93hDlTadYSzQZXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ouvryy/69LaTrik/blob/main/ConvolutionalNeuralNetworkwithPyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y4oGYEdDQ5xF"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    \"\"\"Return GPU device if available, or fall back to CPU\"\"\"\n",
        "\n",
        "    return torch.device(\n",
        "        \"cuda\"\n",
        "        if torch.cuda.is_available()\n",
        "        else \"mps\"\n",
        "        if torch.backends.mps.is_available()\n",
        "        else \"cpu\"\n",
        "    )\n",
        "\n",
        "\n",
        "device = get_device()\n",
        "print(f\"PyTorch {torch.__version__}, using {device} device\")\n",
        "\n",
        "device = get_device()\n",
        "print(f\"PyTorch {torch.__version__}, using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYGE_Bp-ROHp",
        "outputId": "11b99ad7-351a-4907-94b6-6b8caa91d390"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch 2.6.0+cu124, using cuda device\n",
            "PyTorch 2.6.0+cu124, using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "n_epochs = 10  # Number of training iterations on the whole dataset\n",
        "learning_rate = 0.001  # Rate of parameter change during gradient descent\n",
        "batch_size = 64  # Number of samples used for one gradient descent step\n",
        "conv2d_kernel_size = 3  # Size of the 2D convolution kernels"
      ],
      "metadata": {
        "id": "9qeflZmfTtm_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory for downloaded files\n",
        "DATA_DIR = \"./_output\"\n",
        "\n",
        "# Download and construct the Fashion-MNIST images dataset\n",
        "# The training set is used to train the model\n",
        "train_dataset = datasets.FashionMNIST(\n",
        "    root=DATA_DIR,\n",
        "    train=True,  # Training set\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")\n",
        "# The test set is used to evaluate the trained model performance on unseen data\n",
        "test_dataset = datasets.FashionMNIST(\n",
        "    root=DATA_DIR,\n",
        "    train=False,  # Test set\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JgdWNjjT1uv",
        "outputId": "aca53ad7-d3ac-4bc4-aef0-faa438f3afc0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 13.1MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 207kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.92MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loader for loading training data as randomized batches\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "# Number of training samples\n",
        "n_train_samples = len(train_dataloader.dataset)\n",
        "# Number of batches in an epoch (= n_train_samples / batch_size, rounded up)\n",
        "n_batches = len(train_dataloader)\n",
        "assert n_batches == math.ceil(n_train_samples / batch_size)"
      ],
      "metadata": {
        "id": "_RTLx-SjUIzv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loader for loading test data as randomized batches\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_dataset, batch_size=batch_size, shuffle=False\n",
        ")\n",
        "# Number of test samples\n",
        "n_test_samples = len(test_dataloader.dataset)\n",
        "\n",
        "print(f\"{n_train_samples} training samples, {n_test_samples} test samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy_5q7sTUPYH",
        "outputId": "1c64bb2c-b4c8-4380-8d44-71cb27d5c3e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 training samples, 10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Convnet(nn.Module):\n",
        "    \"\"\"Convnet for fashion articles classification\"\"\"\n",
        "\n",
        "    def __init__(self, conv2d_kernel_size=3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define a sequential stack of layers\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            # 2D convolution, output shape: (batch_zize, out_channels, output_dim, output_dim)\n",
        "            # Without padding, output_dim = (input_dim - kernel_size + 1) / stride\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=conv2d_kernel_size),\n",
        "            nn.ReLU(),\n",
        "            # Max pooling, output shape: (batch_zize, out_channels, input_dim // kernel_size, input_dim // kernel_size)\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=conv2d_kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            # Flattening layer, output shape: (batch_zize, out_channels * output_dim * output_dim)\n",
        "            nn.Flatten(),\n",
        "            # Linear layer whose input features are inferred during the first call to forward(). Output shape: (batch_zize, 128).\n",
        "            # This avoids hardcoding the output shape of the previous layer, which depends on the shape of input images\n",
        "            nn.LazyLinear(out_features=128),\n",
        "            nn.ReLU(),\n",
        "            # Output shape: (batch_size, 10)\n",
        "            nn.Linear(in_features=128, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Define the forward pass of the model\"\"\"\n",
        "\n",
        "        # Compute output of layer stack\n",
        "        logits = self.layer_stack(x)\n",
        "\n",
        "        # Logits are a vector of raw (non-normalized) predictions\n",
        "        # This vector contains 10 values, one for each possible class\n",
        "        return logits"
      ],
      "metadata": {
        "id": "FuK7CsABWH-l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the convolutional network\n",
        "model = Convnet(conv2d_kernel_size=conv2d_kernel_size).to(device)\n",
        "\n",
        "# Use the first training image as dummy to initialize the LazyLinear layer.\n",
        "# This is mandatory to count model parameters (see below)\n",
        "first_img, _ = train_dataset[0]\n",
        "# Add a dimension (to match expected shape with batch size) and store tensor on device memory\n",
        "dummy_batch = first_img[None, :].to(device)\n",
        "model(dummy_batch)\n",
        "\n",
        "# Print model architecture\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTza7O0qW3zc",
        "outputId": "02027704-eb61-453a-c7b1-76a022d5ffea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convnet(\n",
            "  (layer_stack): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    (7): Linear(in_features=1600, out_features=128, bias=True)\n",
            "    (8): ReLU()\n",
            "    (9): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameter_count(model):\n",
        "    \"\"\"Return the number of trainable parameters for a PyTorch model\"\"\"\n",
        "\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "# Print model architecture\n",
        "print(model)\n",
        "\n",
        "# Compute and print parameter count\n",
        "n_params = get_parameter_count(model)\n",
        "print(f\"Model has {n_params} trainable parameters\")\n",
        "# Linear layers have (in_features + 1) * out_features parameters\n",
        "print(n_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMxH4f3dXERs",
        "outputId": "008861a9-74ff-43e0-bf17-e75377be49d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convnet(\n",
            "  (layer_stack): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    (7): Linear(in_features=1600, out_features=128, bias=True)\n",
            "    (8): ReLU()\n",
            "    (9): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Model has 225034 trainable parameters\n",
            "225034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and print parameter count\n",
        "n_params = get_parameter_count(model)\n",
        "print(f\"Model has {n_params} trainable parameters\")\n",
        "\n",
        "# Conv2d layers have (in_channels * kernel_size * kernel_size + 1) * out_channels parameters\n",
        "n_params_cond2d1 = (1 * conv2d_kernel_size * conv2d_kernel_size + 1) * 32\n",
        "n_params_cond2d2 = (32 * conv2d_kernel_size * conv2d_kernel_size + 1) * 64\n",
        "\n",
        "# Max-pooling layers have zero parameters\n",
        "\n",
        "# Linear layers have (in_features + 1) * out_features parameters.\n",
        "# To compute in_features for the first linear layer, we have to infer the output shapes of the previous layers.\n",
        "conv2d1_output_dim = 28 - conv2d_kernel_size + 1  # 2D cnvolution with no padding\n",
        "maxpool1_output_dim = conv2d1_output_dim // 2  # Max-pooling with a kernel of size 2\n",
        "conv2d2_output_dim = (\n",
        "    maxpool1_output_dim - conv2d_kernel_size + 1\n",
        ")  # 2D cnvolution with no padding\n",
        "maxpool2_output_dim = conv2d2_output_dim // 2  # 2D cnvolution with no padding\n",
        "# Output shape for the second max-pooling layer: (batch_size, 64, maxpool2_output_dim, maxpool2_output_dim)\n",
        "# Output shape for the flattening layer: (batch_size, 64 * maxpool2_output_dim * maxpool2_output_dim)\n",
        "n_params_linear1 = (64 * maxpool2_output_dim * maxpool2_output_dim + 1) * 128\n",
        "\n",
        "n_params_linear2 = (128 + 1) * 10\n",
        "\n",
        "assert (\n",
        "    n_params\n",
        "    == n_params_cond2d1 + n_params_cond2d2 + n_params_linear1 + n_params_linear2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mawydqNZbqI",
        "outputId": "ab8968d4-da97-49fd-9df9-f34ef498deed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has 225034 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use cross-entropy loss function for this multiclass classification task.\n",
        "# Softmax is computed internally to convert outputs into probabilities\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "AhFYt-2cZnPo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam optimizer for gradient descent\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "3IcPN1UIZtCY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to training mode - important for batch normalization and dropout layers.\n",
        "# Unnecessary here but added for best practices\n",
        "model.train()\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(n_epochs):\n",
        "    # Total loss for epoch, divided by number of batches to obtain mean loss\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Number of correct predictions in an epoch, used to compute epoch accuracy\n",
        "    n_correct = 0\n",
        "\n",
        "    for x_batch, y_batch in train_dataloader:\n",
        "        # Copy batch data to GPU memory (if available)\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(x_batch)\n",
        "\n",
        "        # Compute loss value\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "\n",
        "        # Gradient descent step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Accumulate data for epoch metrics: loss and number of correct predictions\n",
        "            epoch_loss += loss.item()\n",
        "            n_correct += (\n",
        "                (model(x_batch).argmax(dim=1) == y_batch).float().sum().item()\n",
        "            )\n",
        "\n",
        "    # Compute epoch metrics\n",
        "    mean_loss = epoch_loss / n_batches\n",
        "    epoch_acc = n_correct / n_train_samples\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{(epoch + 1):3}/{n_epochs:3}] finished. Mean loss: {mean_loss:.5f}. Accuracy: {epoch_acc * 100:.2f}%\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4MpOISPZu5w",
        "outputId": "3df3abdb-f026-446e-85d9-accf200e52b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [  1/ 10] finished. Mean loss: 0.52666. Accuracy: 81.47%\n",
            "Epoch [  2/ 10] finished. Mean loss: 0.34637. Accuracy: 87.98%\n",
            "Epoch [  3/ 10] finished. Mean loss: 0.29558. Accuracy: 89.71%\n",
            "Epoch [  4/ 10] finished. Mean loss: 0.26351. Accuracy: 90.97%\n",
            "Epoch [  5/ 10] finished. Mean loss: 0.23932. Accuracy: 91.69%\n",
            "Epoch [  6/ 10] finished. Mean loss: 0.21607. Accuracy: 92.58%\n",
            "Epoch [  7/ 10] finished. Mean loss: 0.19885. Accuracy: 93.29%\n",
            "Epoch [  8/ 10] finished. Mean loss: 0.18077. Accuracy: 93.91%\n",
            "Epoch [  9/ 10] finished. Mean loss: 0.16586. Accuracy: 94.58%\n",
            "Epoch [ 10/ 10] finished. Mean loss: 0.15133. Accuracy: 95.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode - important for batch normalization and dropout layers.\n",
        "# Unnecessary here but added for best practices\n",
        "model.eval()\n",
        "\n",
        "# Compute model accuracy on test data\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "\n",
        "    for x_batch, y_batch in test_dataloader:\n",
        "        # Copy batch data to GPU memory (if available)\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        y_pred = model(x_batch)\n",
        "        n_correct += (model(x_batch).argmax(dim=1) == y_batch).float().sum().item()\n",
        "\n",
        "    test_acc = n_correct / len(test_dataloader.dataset)\n",
        "    print(f\"Test accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXR5wz0sZ9AY",
        "outputId": "0ba3c0a5-14c6-452e-e7f1-875dc1ea877c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 90.76%\n"
          ]
        }
      ]
    }
  ]
}